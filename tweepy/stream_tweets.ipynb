{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stream tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "from os.path import join\n",
    "sys.path.insert(1, 'C:\\\\Users\\\\raide\\\\OneDrive\\\\Documents\\\\GitHub\\\\capstone_project\\\\scraping')\n",
    "sys.path.insert(1, 'C:\\\\Users\\\\raide\\\\OneDrive\\\\Documents\\\\GitHub\\\\capstone_project\\\\constants')\n",
    "from scrape_hashtags import get_hashtag_stats\n",
    "from constants import get_matteo_twitter_creds, get_michael_twitter_creds\n",
    "\n",
    "access_token, access_token_secret, consumer_key, consumer_secret = get_michael_twitter_creds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get hashtag data\n",
    "Using food words from [Enchanted Learning](https://www.enchantedlearning.com/wordlist/food.shtml), we can capture an abundance of food words and supply them to the [RiteKit's hashtag comparer](https://ritekit.com/developer/login/) to learn about the statistics of the hashtag over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtag</th>\n",
       "      <th>unique_tweets_per_hour</th>\n",
       "      <th>retweets_per_hour</th>\n",
       "      <th>views_per_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple</td>\n",
       "      <td>129</td>\n",
       "      <td>96</td>\n",
       "      <td>351000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>avocado</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bake</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>20458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>banana</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>2542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>barbecue</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>wok</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>yeast</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>yogurt</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>yolk</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>zucchini</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>465 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hashtag  unique_tweets_per_hour  retweets_per_hour  views_per_hour\n",
       "0       apple                     129                 96          351000\n",
       "1     avocado                       4                  0            9800\n",
       "2        bake                      12                  0           20458\n",
       "3      banana                      12                  5            2542\n",
       "4    barbecue                       4                  0            7462\n",
       "..        ...                     ...                ...             ...\n",
       "460       wok                       0                  4               0\n",
       "461     yeast                       4                  0             333\n",
       "462    yogurt                       4                  0            4346\n",
       "463      yolk                       0                  4               0\n",
       "464  zucchini                       4                  0            4488\n",
       "\n",
       "[465 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Capture food words from https://www.enchantedlearning.com/wordlist/food.shtml\n",
    "df = get_hashtag_stats()\n",
    "df[['unique_tweets_per_hour', 'retweets_per_hour', 'views_per_hour']] = df[['unique_tweets_per_hour', 'retweets_per_hour', 'views_per_hour']].apply(pd.to_numeric)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract words and words as hashtags\n",
    "all_words = df.hashtag.tolist()\n",
    "all_hashtags = ['#' + s for s in all_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of the 465 hashtags in the raw data, 20 received >= 100000 views.\n"
     ]
    }
   ],
   "source": [
    "# Filter hashtags by those that have been viewed more than 100K times in the past hour\n",
    "exposed_hashtags = df[df.views_per_hour >= 100000]\n",
    "exposed_hashtags_words = [s for s in exposed_hashtags.hashtag.tolist()]\n",
    "exposed_hashtags_hashtags = ['#' + s for s in exposed_hashtags_words]\n",
    "exposed_hashtags_and_words = exposed_hashtags_words + exposed_hashtags_hashtags\n",
    "print(f\"Out of the {df.shape[0]} hashtags in the raw data, {exposed_hashtags.shape[0]} received >= 100000 views.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a wrapper for tweepy.Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoodScraper(tweepy.Stream):\n",
    "    \n",
    "    # Create ability to specify a time limit in seconds for the scrape to run\n",
    "    def __init__(self, consumer_key, consumer_secret, access_token, access_token_secret, max_retries, time_limit):\n",
    "        self.max_retries = max_retries\n",
    "        self.time_limit = time_limit\n",
    "        self.start_time = time.time()\n",
    "        self.captured_tweets = 0\n",
    "        self.missed_tweets = 0\n",
    "        super().__init__(consumer_key, consumer_secret, access_token, access_token_secret) # required for tweepy.Stream\n",
    "        \n",
    "    # Create dataframe when connection is established\n",
    "    def on_connect(self):\n",
    "        self.df = pd.DataFrame(columns = [  'created_at',\n",
    "                                            'tweet_id',\n",
    "                                            'user_id',\n",
    "                                            'user_name',\n",
    "                                            'screen_name',\n",
    "                                            'verified',\n",
    "                                            'text',\n",
    "                                            'quote_tweet',\n",
    "                                            'rewteet_count',\n",
    "                                            'favorite_count',\n",
    "                                            'place',\n",
    "                                            'quote_status_id',\n",
    "                                            'entities'])\n",
    "        \n",
    "    # When a tweet is retrieved, capture its information in a list and add it to the dataframe\n",
    "    def on_status(self, status):\n",
    "        # Limit stream runtime\n",
    "        if time.time() - self.start_time < self.time_limit:\n",
    "            try:\n",
    "                self.captured_tweets += 1\n",
    "                created_at = status.created_at\n",
    "                tweet_id = status.id\n",
    "                user_id = status.user.id\n",
    "                user_name = status.user.name\n",
    "                screen_name = status.user.screen_name\n",
    "                verified = status.user.verified\n",
    "                text = status.text\n",
    "                quote_tweet = status.is_quote_status\n",
    "                rewteet_count = status.retweet_count\n",
    "                favorite_count = status.favorite_count\n",
    "                \n",
    "                # Not nullable fields\n",
    "                try:\n",
    "                    place = status.place\n",
    "                    quote_status_id = status.quoted_status_id\n",
    "                    hashtags = status.entities.hashtags\n",
    "                except:\n",
    "                    place = None\n",
    "                    quote_status_id = None\n",
    "                    hashtags = None\n",
    "\n",
    "                # Create list of tweet info\n",
    "                self.tweets = [ created_at,\n",
    "                                tweet_id,\n",
    "                                user_id,\n",
    "                                user_name,\n",
    "                                screen_name,\n",
    "                                verified,\n",
    "                                text,\n",
    "                                quote_tweet,\n",
    "                                rewteet_count,\n",
    "                                favorite_count,\n",
    "                                place,\n",
    "                                quote_status_id,\n",
    "                                hashtags]\n",
    "                \n",
    "                # Add tweet info to dataframe\n",
    "                self.df.loc[len(self.df)] = self.tweets\n",
    "                \n",
    "                # Count tweets\n",
    "                self.captured_tweets += 1\n",
    "                print(f'Tweets streamed: {self.captured_tweets}')\n",
    "            \n",
    "            # If an error occurs, write the data to the directory and disconnect the stream\n",
    "            except:\n",
    "                to_csv_timestamp = datetime.today().strftime('%Y%m%d_%H%M%S_')\n",
    "                path = r'C:\\Users\\raide\\OneDrive\\Documents\\GitHub\\capstone_project\\data\\stream\\enchanted_food_list'\n",
    "                filename = '\\\\' + to_csv_timestamp + 'exposed_food_tweets.csv'\n",
    "                self.df.to_csv(path + filename, index=False)\n",
    "                self.disconnect()\n",
    "                \n",
    "        # When the time limit is reached\n",
    "        else:\n",
    "            to_csv_timestamp = datetime.today().strftime('%Y%m%d_%H%M%S_')\n",
    "            path = r'C:\\Users\\raide\\OneDrive\\Documents\\GitHub\\capstone_project\\data\\stream\\enchanted_food_list'\n",
    "            filename = '\\\\' + to_csv_timestamp + 'exposed_food_tweets.csv'\n",
    "            self.df.to_csv(path + filename, index=False)\n",
    "            self.disconnect()\n",
    "    \n",
    "    # Exception handling\n",
    "    def on_limit(self, track):\n",
    "        self.missed_tweets += track\n",
    "\n",
    "    def on_connection_error(self):\n",
    "        self.disconnect()\n",
    "        try:\n",
    "            print(f'Stream has disconnected.\\nNumber of tweets streamed: {self.captured_tweets}\\nNumber of tweets missed: {self.missed_tweets}\\nPercent of tweets streamed that were missed: {self.missed_tweets / self.captured_tweets * 100}')\n",
    "        except:\n",
    "            print('No tweets were found')\n",
    "        return \n",
    "        \n",
    "    def on_closed(self, response):\n",
    "        print('Response', response)\n",
    "        self.disconnect()\n",
    "        print('\\nConnection has closed')\n",
    "        return \n",
    "    \n",
    "    def on_disconnect(self):\n",
    "        self.disconnect()\n",
    "        try:\n",
    "            print(f'Stream has disconnected.\\nNumber of tweets streamed: {self.captured_tweets}\\nNumber of tweets missed: {self.missed_tweets}\\nPercent of tweets streamed that were missed: {self.missed_tweets / self.captured_tweets * 100}')\n",
    "        except:\n",
    "            print('No tweets were found')\n",
    "        return \n",
    "    \n",
    "    def on_exception(self, exception):\n",
    "        print('An exception occurred:', exception)\n",
    "        try:\n",
    "            print(f'Stream has disconnected.\\nNumber of tweets streamed: {self.captured_tweets}\\nNumber of tweets missed: {self.missed_tweets}\\nPercent of tweets streamed that were missed: {self.missed_tweets / self.captured_tweets * 100}')\n",
    "        except:\n",
    "            print('No tweets were found')\n",
    "        return \n",
    "        \n",
    "    def on_request_error(self, status_code):\n",
    "        print('An error occurred:', status_code)\n",
    "        try:\n",
    "            print(f'Stream has disconnected.\\nNumber of tweets streamed: {self.captured_tweets}\\nNumber of tweets missed: {self.missed_tweets}\\nPercent of tweets streamed that were missed: {self.missed_tweets / self.captured_tweets * 100}')\n",
    "        except:\n",
    "            print('No tweets were found')\n",
    "        return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the scraper and run for a specified length of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_scraper = FoodScraper(consumer_key, consumer_secret, access_token, access_token_secret, max_retries=10, time_limit=3600)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop to run for however long you'd like\n",
    "\n",
    "# Run for a day\n",
    "for i in range(0, 24):\n",
    "    # food_scraper = FoodScraper(consumer_key, consumer_secret, access_token, access_token_secret, max_retries=10, time_limit=3600)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "05811a4c8edeb62e87c3e708461cae05c65dc4bb514779bc955273fc84b8bc5c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
