{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stream tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "from os.path import join\n",
    "sys.path.insert(1, 'C:\\\\Users\\\\raide\\\\OneDrive\\\\Documents\\\\GitHub\\\\capstone_project\\\\scraping')\n",
    "sys.path.insert(1, 'C:\\\\Users\\\\raide\\\\OneDrive\\\\Documents\\\\GitHub\\\\capstone_project\\\\constants')\n",
    "from scrape_hashtags import get_hashtag_stats\n",
    "from constants import get_matteo_twitter_creds, get_michael_twitter_creds\n",
    "\n",
    "access_token, access_token_secret, consumer_key, consumer_secret = get_michael_twitter_creds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a wrapper for tweepy.Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoodStreamer(tweepy.Stream):\n",
    "    \n",
    "    # Create ability to specify a time limit in seconds for the scrape to run\n",
    "    def __init__(self, consumer_key, consumer_secret, access_token, access_token_secret, max_retries, time_limit, path):\n",
    "        self.max_retries = max_retries\n",
    "        self.time_limit = time_limit\n",
    "        self.start_time = time.time()\n",
    "        self.captured_tweets = 0\n",
    "        self.missed_tweets = 0\n",
    "        self.run_path = path\n",
    "        self.run_begin_time = datetime.today().strftime('%Y%m%d_%H%M%S_')\n",
    "        super().__init__(consumer_key, consumer_secret, access_token, access_token_secret) # required for tweepy.Stream\n",
    "        \n",
    "    # Create dataframe when connection is established\n",
    "    def on_connect(self):\n",
    "        print('Stream has connected.\\n')\n",
    "        self.df = pd.DataFrame(columns = [  'created_at',\n",
    "                                            'tweet_id',\n",
    "                                            'user_id',\n",
    "                                            'user_name',\n",
    "                                            'screen_name',\n",
    "                                            'verified',\n",
    "                                            'text',\n",
    "                                            'quote_tweet',\n",
    "                                            'rewteet_count',\n",
    "                                            'favorite_count',\n",
    "                                            'place',\n",
    "                                            'quote_status_id',\n",
    "                                            'entities'])\n",
    "        \n",
    "    # When a tweet is retrieved, capture its information in a list and add it to the dataframe\n",
    "    def on_status(self, status):\n",
    "        # Limit stream runtime\n",
    "        if time.time() - self.start_time < self.time_limit:\n",
    "            try:\n",
    "                created_at = status.created_at\n",
    "                tweet_id = status.id\n",
    "                user_id = status.user.id\n",
    "                user_name = status.user.name\n",
    "                screen_name = status.user.screen_name\n",
    "                verified = status.user.verified\n",
    "                text = status.text\n",
    "                quote_tweet = status.is_quote_status\n",
    "                rewteet_count = status.retweet_count\n",
    "                favorite_count = status.favorite_count\n",
    "                \n",
    "                # Not nullable fields\n",
    "                try:\n",
    "                    place = status.place\n",
    "                except:\n",
    "                    place = None\n",
    "                try:\n",
    "                    quote_status_id = status.quoted_status_id\n",
    "                except:\n",
    "                    quote_status_id = None\n",
    "                try:\n",
    "                    entities = status.entities\n",
    "                except:\n",
    "                    entities = None\n",
    "\n",
    "                # Create list of tweet info\n",
    "                self.tweets = [ created_at,\n",
    "                                tweet_id,\n",
    "                                user_id,\n",
    "                                user_name,\n",
    "                                screen_name,\n",
    "                                verified,\n",
    "                                text,\n",
    "                                quote_tweet,\n",
    "                                rewteet_count,\n",
    "                                favorite_count,\n",
    "                                place,\n",
    "                                quote_status_id,\n",
    "                                entities]\n",
    "                \n",
    "                # Add tweet info to dataframe\n",
    "                self.df.loc[len(self.df)] = self.tweets\n",
    "                \n",
    "                # Count tweets\n",
    "                self.captured_tweets += 1\n",
    "                print(f'Tweets streamed: {self.captured_tweets}')\n",
    "            \n",
    "            # If an error occurs, write the data to the directory and disconnect the stream\n",
    "            except:\n",
    "                filename = os.path.join(self.run_path, self.run_begin_time + 'exposed_food_tweets.csv')\n",
    "                self.df.to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "                self.disconnect()\n",
    "                \n",
    "        # When the time limit is reached\n",
    "        else:\n",
    "            filename = os.path.join(self.run_path, self.run_begin_time + 'exposed_food_tweets.csv')\n",
    "            self.df.to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "            self.disconnect()\n",
    "    \n",
    "    # Exception handling\n",
    "    def on_limit(self, track):\n",
    "        print('Limit has been reached...waiting...')\n",
    "        self.missed_tweets += track\n",
    "\n",
    "    def on_connection_error(self):\n",
    "        print('on_connection_error')\n",
    "    \n",
    "    def on_exception(self, exception):\n",
    "        print('An exception occurred:', exception)\n",
    "        \n",
    "    def on_request_error(self, status_code):\n",
    "        print('An error occurred:', status_code)\n",
    "            \n",
    "    def on_closed(self, response):\n",
    "        print('Response', response)\n",
    "        print('\\nConnection has closed')\n",
    "    \n",
    "    def on_disconnect(self):\n",
    "        f = open(os.path.join(self.run_path, self.run_begin_time + 'results.txt'),\"w+\")\n",
    "        f.write(f\"Number of tweets streamed: {self.captured_tweets}\\nNumber of tweets missed: {self.missed_tweets}\\nPercent of tweets streamed that were missed: {self.missed_tweets / self.captured_tweets * 100}\")\n",
    "        f.close()\n",
    "        try:\n",
    "            print(f'Stream has disconnected.\\nNumber of tweets streamed: {self.captured_tweets}\\nNumber of tweets missed: {self.missed_tweets}\\nPercent of tweets streamed that were missed: {self.missed_tweets / self.captured_tweets * 100}')\n",
    "        except:\n",
    "            print('No tweets were found') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get hashtag data\n",
    "Using food words from [Enchanted Learning](https://www.enchantedlearning.com/wordlist/food.shtml), we can capture an abundance of food words and supply them to the [RiteKit's hashtag comparer](https://ritekit.com/developer/login/) to learn about the statistics of the hashtag over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_query(hashtag_list, food_list, cutoff):\n",
    "    \"\"\"\n",
    "    Calls scraping function `get_hashtag_stats` and adds supplied list of hashtags to the query for hashtag statistics. Returns a list of words whose hashtags (i.e., input 'python', check stats for '#python') have received >100K views in the last hour.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    hashtag_list (list): A list of strings of hashtags to get statistics on.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    exposed_hashtag_words (list): A list of strings of words where the hashtag of that word received >100K views in the past hour.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Scrape for hashtags\n",
    "    df = get_hashtag_stats(hashtags=hashtag_list, food_list=food_list)\n",
    "    \n",
    "    # Extract words and words as hashtags\n",
    "    all_words = df.hashtag.tolist()\n",
    "    all_hashtags = ['#' + s for s in all_words]\n",
    "    \n",
    "    # Filter hashtags by those that have been viewed more than 100K times in the past hour AND include those that we specified\n",
    "    exposed_hashtags = df[(df.views_per_hour >= cutoff) | (df.hashtag.isin(hashtag_list))]\n",
    "    exposed_hashtags_words = [s for s in exposed_hashtags.hashtag.tolist()]\n",
    "    exposed_hashtags_hashtags = ['#' + s for s in exposed_hashtags_words]\n",
    "    exposed_hashtags_and_words = exposed_hashtags_words + exposed_hashtags_hashtags\n",
    "    print(f\"Out of the {df.shape[0]} hashtags in the raw data, {exposed_hashtags.shape[0]} received >= {cutoff} views.\")\n",
    "    \n",
    "    return exposed_hashtags_words, exposed_hashtags_hashtags, exposed_hashtags_and_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the scraper and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_tweets(hashtag_list, time_limit, loops, max_retries):\n",
    "    # Create directory to save the runs to\n",
    "    abspath = os.getcwd()\n",
    "    data_path = os.path.join(abspath, 'data')\n",
    "    run_begin_time = datetime.today().strftime('%Y%m%d_%H%M%S_')\n",
    "    run_path = os.path.join(data_path, run_begin_time + 'run')\n",
    "    os.mkdir(run_path)\n",
    "\n",
    "    # Run for seconds in `time_limit`\n",
    "    time_limit = time_limit\n",
    "    max_retries = max_retries    \n",
    "\n",
    "    # Loop to run for however many repeats over time set in time_limit\n",
    "    for loop in range(0, loops):\n",
    "        food_streamer = FoodStreamer(consumer_key, consumer_secret, access_token, access_token_secret, max_retries=max_retries, time_limit=time_limit, path=run_path) \n",
    "        exposed_hashtags_words, exposed_hashtags_hashtags, exposed_hashtags_and_words = stream_query(hashtag_list=hashtag_list, food_list=False)\n",
    "        try:\n",
    "            food_streamer.filter(track=exposed_hashtags_hashtags, languages=['en'])\n",
    "        except:\n",
    "            pass\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23860/1005673258.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mhashtag_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'foodie'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'foodporn'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'food'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'delicious'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'love'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'recipes'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'eating'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'recipe'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cook'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cooking'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'restaurant'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'vegan'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'breakfast'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lunch'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'foodgasm'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'foodies'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'nomnomnom'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'dinner'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mstream_tweets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhashtag_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3600\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloops\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_retries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23860/2841191315.py\u001b[0m in \u001b[0;36mstream_tweets\u001b[1;34m(hashtag_list, time_limit, loops, max_retries)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mloop\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloops\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mfood_streamer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFoodStreamer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconsumer_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsumer_secret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccess_token\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccess_token_secret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_retries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime_limit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrun_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mexposed_hashtags_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexposed_hashtags_hashtags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexposed_hashtags_and_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstream_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhashtag_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhashtag_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfood_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mfood_streamer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexposed_hashtags_hashtags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'en'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23860/2942288358.py\u001b[0m in \u001b[0;36mstream_query\u001b[1;34m(hashtag_list, food_list)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# Scrape for hashtags\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_hashtag_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhashtags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhashtag_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfood_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfood_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# Extract words and words as hashtags\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\GitHub\\capstone_project\\scraping\\scrape_hashtags.py\u001b[0m in \u001b[0;36mget_hashtag_stats\u001b[1;34m(hashtags, food_list)\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[0mdriver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchrome_driver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://ritetag.com/hashtag-comparison/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mhashtag_url_str\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hashtag_list=['foodie', 'foodporn', 'food', 'delicious', 'love', 'recipes', 'eating', 'recipe', 'cook', 'cooking', 'restaurant', 'vegan', 'breakfast', 'lunch', 'foodgasm', 'foodies', 'nomnomnom', 'dinner']\n",
    "\n",
    "stream_tweets(hashtag_list, time_limit=3600, loops=14, max_retries=10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "05811a4c8edeb62e87c3e708461cae05c65dc4bb514779bc955273fc84b8bc5c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
